"""
Django settings for backend project.

Generated by 'django-admin startproject' using Django 3.2.9.

For more information on this file, see
https://docs.djangoproject.com/en/3.2/topics/settings/

For the full list of settings and their values, see
https://docs.djangoproject.com/en/3.2/ref/settings/
"""

import csv
import os
import sys
from pathlib import Path

from decouple import Csv, config
from django.conf import settings
from django.utils import timezone

# Build paths inside the project like this: BASE_DIR / 'subdir'.
BASE_DIR = Path(__file__).resolve().parent.parent

ANTEON_ENV = config('ANTEON_ENV', default='onprem')
# MAX_UPLOAD_SIZE = config('MAX_UPLOAD_SIZE', default=33554432, cast=int)  # byte: 1024 * 1024 * 32 = 32MB
# MAX_TEST_DATA_UPLOAD_SIZE = config('MAX_TEST_DATA_UPLOAD_SIZE', default=67108864, cast=int)  # byte: 1024 * 1024 * 64 = 64MB

# Quick-start development settings - unsuitable for production
# See https://docs.djangoproject.com/en/3.2/howto/deployment/checklist/

# SECURITY WARNING: keep the secret key used in production secret!
SECRET_KEY = config(
    'SECRET_KEY', default='asf12rwASFeJQtasfasxW27Y0Dzasfasfasfasq1rn2rasfaf21rqwfasfsafasFSAFaswETGzsa214rqfsa')

# SECURITY WARNING: don't run with debug turned on in production!
DEBUG = config('DEBUG', default=False, cast=bool)
PRODUCTION = config('PRODUCTION', default=True, cast=bool)
SENTRY_ENABLED = config('SENTRY_ENABLED', default=False, cast=bool)
VERBOSE_LOG = config("VERBOSE_LOG", cast=bool, default=False)

if SENTRY_ENABLED:
    import sentry_sdk
    from sentry_sdk.integrations.celery import CeleryIntegration
    from sentry_sdk.integrations.django import DjangoIntegration
    SENTRY_DSN = config('SENTRY_DSN')
    sentry_sdk.init(
        dsn=SENTRY_DSN,
        integrations=[
            DjangoIntegration(), 
            CeleryIntegration(
                monitor_beat_tasks=False,
                exclude_beat_tasks=[
                    # "unimportant-task",
                    # "payment-check-.*"
                ],
                )
        ],
        traces_sample_rate=0.05,
        send_default_pii=True,
        environment=ANTEON_ENV,
    )


if DEBUG:
    EMAIL_BACKEND = 'django.core.mail.backends.console.EmailBackend'

ALLOWED_HOSTS = config('ALLOWED_HOSTS', cast=Csv(), default='*')

AUTH_USER_MODEL = "accounts.User"

# Application definition
INSTALLED_APPS = [
    'daphne',
    'channels',

    'django.contrib.admin',
    'django.contrib.auth',
    'django.contrib.contenttypes',
    'django.contrib.sessions',
    'django.contrib.messages',
    'django.contrib.staticfiles',
    'django_filters',
    'django_extensions',

    'core.apps.CoreConfig',
    'accounts.apps.AccountsConfig',
    'analytics.apps.AnalyticsConfig',
    'dist_tracing.apps.DistTracingConfig',
    'pricing.apps.PricingConfig',

    'rest_framework',
    'corsheaders',
    'django_celery_beat',
    'django_celery_results',
    'dbconnectionretrier',
]

MIDDLEWARE = [
    'django.middleware.gzip.GZipMiddleware',
    'django.middleware.security.SecurityMiddleware',
    'django.contrib.sessions.middleware.SessionMiddleware',
    'whitenoise.middleware.WhiteNoiseMiddleware',
    'django.middleware.common.CommonMiddleware',
    'django.middleware.csrf.CsrfViewMiddleware',
    'django.contrib.auth.middleware.AuthenticationMiddleware',
    'django.contrib.messages.middleware.MessageMiddleware',
    'django.middleware.clickjacking.XFrameOptionsMiddleware',
    'corsheaders.middleware.CorsMiddleware',
    # 'backend.middlewares.MemoryUsageMiddleware'
    # 'backend.middlewares.LogUrlMiddleware'
]

if VERBOSE_LOG:
    MIDDLEWARE.append('backend.middlewares.LogBadRequestMiddleware')

ROOT_URLCONF = 'backend.urls'

TEMPLATES = [
    {
        'BACKEND': 'django.template.backends.django.DjangoTemplates',
        'DIRS': [],
        'APP_DIRS': True,
        'OPTIONS': {
            'context_processors': [
                'django.template.context_processors.debug',
                'django.template.context_processors.request',
                'django.contrib.auth.context_processors.auth',
                'django.contrib.messages.context_processors.messages',
            ],
        },
    },
]

WSGI_APPLICATION = 'backend.wsgi.application'


# Database
# https://docs.djangoproject.com/en/3.2/ref/settings/#databases

db_name = config('POSTGRES_DB_NAME', default="alazbackend")
host = config('POSTGRES_HOST', default="postgres")
host_read_replica = config('POSTGRES_HOST_READ_REPLICA', default="")
port = config('POSTGRES_PORT', default=5432, cast=int)
db_password = config('POSTGRES_PASSWORD', default="ChangeMe")
DATABASES = {
    'default': {
        'ENGINE': 'django.db.backends.postgresql',
        'NAME': db_name,
        'USER': config('POSTGRES_USER', default='postgres'),
        'PASSWORD': db_password,
        'HOST': host,
        'PORT': port,
        'OPTIONS': {
            'options': '-c application_name=main'
        },
        # 'OPTIONS': {
        #     'isolation_level': psycopg2.extensions.ISOLATION_LEVEL_READ_UNCOMMITTED,
        # },
    },
    'core_tasks': {
        'ENGINE': 'django.db.backends.postgresql',
        'NAME': db_name,
        'USER': config('POSTGRES_USER', default='postgres'),
        'PASSWORD': db_password,
        'HOST': host,
        'PORT': port,
        'OPTIONS': {
            'options': '-c application_name=core_tasks'
        },
    },
    'dist_tracing_tasks': {
        'ENGINE': 'django.db.backends.postgresql',
        'NAME': db_name,
        'USER': config('POSTGRES_USER', default='postgres'),
        'PASSWORD': db_password,
        'HOST': host,
        'PORT': port,
        'OPTIONS': {
            'options': '-c application_name=dist_tracing_tasks'
        },
    },
    'request_writer': {
        'ENGINE': 'django.db.backends.postgresql',
        'NAME': db_name,
        'USER': config('POSTGRES_USER', default='postgres'),
        'PASSWORD': db_password,
        'HOST': host,
        'PORT': port,
        'OPTIONS': {
            'options': '-c application_name=request_writer'
        },
    }
}

if host_read_replica:
    DATABASES['read_replica'] = {
        'ENGINE': 'django.db.backends.postgresql',
        'NAME': db_name,
        'USER': config('POSTGRES_USER', default='postgres'),
        'PASSWORD': db_password,
        'HOST': host_read_replica,
        'PORT': port,
    }

DATABASE_ROUTERS = ['backend.routers.PrimaryReplicaRouter']

# Password validation
# https://docs.djangoproject.com/en/3.2/ref/settings/#auth-password-validators

AUTH_PASSWORD_VALIDATORS = [
    {
        'NAME': 'django.contrib.auth.password_validation.UserAttributeSimilarityValidator',
    },
    {
        'NAME': 'django.contrib.auth.password_validation.MinimumLengthValidator',
    },
    {
        'NAME': 'django.contrib.auth.password_validation.CommonPasswordValidator',
    },
    {
        'NAME': 'django.contrib.auth.password_validation.NumericPasswordValidator',
    },
]


# Internationalization
# https://docs.djangoproject.com/en/3.2/topics/i18n/

LANGUAGE_CODE = 'en-us'

TIME_ZONE = 'UTC'

USE_I18N = True

USE_L10N = True

USE_TZ = True


# Default primary key field type
# https://docs.djangoproject.com/en/3.2/ref/settings/#default-auto-field

DEFAULT_AUTO_FIELD = 'django.db.models.BigAutoField'

REST_FRAMEWORK = {
    'DEFAULT_FILTER_BACKENDS': ['django_filters.rest_framework.DjangoFilterBackend'],
    'DEFAULT_PAGINATION_CLASS': 'rest_framework.pagination.PageNumberPagination',
    # This is required to be able to access the endpoints even if they do not have any authentication (or basic authentication)
    'DEFAULT_AUTHENTICATION_CLASSES': (
        'rest_framework_simplejwt.authentication.JWTAuthentication',
    ),
    'DEFAULT_RENDERER_CLASSES': (
        'rest_framework.renderers.JSONRenderer',
    ),
    'PAGE_SIZE': 100000
}

TEST_OUTPUT_VERBOSE = True
TEST_OUTPUT_DIR = 'test_xml_runner'
CELERY_BROKER_HOST = config('CELERY_BROKER_HOST', default='rabbitmq')
CELERY_BROKER_PORT = config('CELERY_BROKER_PORT', default=5672, cast=int)
CELERY_BROKER_URL = f"amqp://{CELERY_BROKER_HOST}:{CELERY_BROKER_PORT}"
CELERY_ACCEPT_CONTENT = ['json']
CELERY_TASK_DEFAULT_QUEUE='alaz-backend-queue'
CELERY_ENABLE_UTC = True
CELERY_TASK_DEFAULT_QUEUE='alaz-backend-queue'
CELERY_RESULT_BACKEND = 'django-db' # django_celery_results
CELERY_RESULT_EXTENDED=True


SWAGGER_SETTINGS = {
    'SECURITY_DEFINITIONS': {
        'Bearer': {
            'type': 'apiKey',
            'in': 'header',
            'name': 'Authorization'
        }
    },
    'USE_SESSION_AUTH': False,
    'JSON_EDITOR': True,

    "is_authenticated": False,
    "is_superuser": False,
    'unauthenticated_user': 'django.contrib.auth.models.AnonymousUser',
}

STATIC_URL = '/static/'

STATIC_ROOT = os.path.join(BASE_DIR, 'static')

if ANTEON_ENV == "onprem":
    STATIC_URL = 'api-alaz/static/'
    STATIC_ROOT = os.path.join(BASE_DIR, 'api-alaz/static')
    CSRF_TRUSTED_ORIGINS = ['http://localhost:8014', 'http://localhost:3000',
                            'https://staging-backend-onprem-cf.ddosify.com',
                            'http://selfhosted-tailscale.ddosify.com:8014',
                            'https://selfhosted.ddosify.com',
                            'http://selfhosted-tailscale.getanteon.com:8014',
                            'https://staging-backend-onprem-cf.getanteon.com',]


REDIS_HOST = config('REDIS_HOST', default='redis-alaz-backend')
REDIS_PORT = config('REDIS_PORT', default=6379, cast=int)

# Required for throttling
CACHES = {
    'alternate': {
        'BACKEND': 'django.core.cache.backends.redis.RedisCache',
        'LOCATION': f'redis://{REDIS_HOST}:{REDIS_PORT}',
    },
    'default': {
        'BACKEND': 'django.core.cache.backends.locmem.LocMemCache',
        'LOCATION': 'unique-snowflake',
    },
}

PASSWORD_RESET_TIMEOUT = 60 * 60 * 24 * 1  # 1 day in seconds. Default 3 days.

APP_NAME = config('APP_NAME', default='alaz-backend')

LOGGING_HANDLER = 'console_prod' if ANTEON_ENV == "production" else 'console_dev'
LOGGING = {
    'version': 1,
    'disable_existing_loggers': False,
    'formatters': {
        'json': {
            '()': 'backend.logger.CustomFormatter',
            'format': '%(asctime)s %(levelname)s %(name)s %(message)s',
        },
        'dev': {
            'format': '%(asctime)s %(levelname)s %(name)s %(message)s',
        },
    },
    'handlers': {
        'console_dev': {
            'level': 'INFO',
            'class': 'logging.StreamHandler',
            'formatter': 'dev'
        },
        'console_prod': {
            'level': 'INFO',
            'class': 'logging.StreamHandler',
            'formatter': 'json'
        },
    },
    'loggers': {
        '': {
            'handlers': [LOGGING_HANDLER],
            'level': 'INFO',
            'propagate': False,
        },
        'django': {
            'handlers': [LOGGING_HANDLER],
            'level': 'INFO',
            'propagate': False,
        },
        'pika': {
            'level': 'WARNING',
            'propagate': False,
        },
        'celery.beat': {
            'level': 'WARNING',
            'propagate': False,
        },
        'celery.app.trace': {
            'level': 'WARNING',
            'propagate': False,
        },
        'celery.worker.strategy': {
            'level': 'WARNING',
            'propagate': False,
        },
    },
}


# INTERNAL_ACCESS_API_KEY = config('INTERNAL_ACCESS_API_KEY', default='ZY2f3bSR0Zzd9Q5t8uRuOZcWw3n8MSI3pW7BGsX3qRFtnLXfF')

# security
CORS_ORIGIN_ALLOW_ALL = True

if ANTEON_ENV == "production":
    CORS_ORIGIN_ALLOW_ALL = False
    CORS_ALLOWED_ORIGINS = [
        'https://app.getanteon.com',
        'https://checker.getanteon.com',
        'https://app.ddosify.com',
        'https://checker.ddosify.com'
    ]
    SECURE_PROXY_SSL_HEADER = ('HTTP_X_FORWARDED_PROTO', 'https')
elif ANTEON_ENV == "onprem":
    CORS_ORIGIN_ALLOW_ALL = True
else:
    CORS_ORIGIN_ALLOW_ALL = False
    CORS_ALLOWED_ORIGIN_REGEXES = [
        r"^(http://staging.ddosify.com:8888)$",
        r"^(http://localhost:30[0-9]{2})$",
        r"^https://(.+).ddosify-frontend.pages.dev$",
        r"^https://(.+).getanteon.com$",
        r"^https://(.+).getanteon-frontend.pages.dev$",
    ]
    SECURE_PROXY_SSL_HEADER = ('HTTP_X_FORWARDED_PROTO', 'https')

USE_X_FORWARDED_HOST = True
USE_X_FORWARDED_PORT = True
LATENCY_REQUEST_COUNT_COST = 5000
LATENCY_DURATION_COST = 0

CONCURRENCY_THROTTLE_RATE = config('CONCURRENCY_THROTTLE_RATE', default='10/s')
CONCURRENCY_GET_THROTTLE_RATE = config('CONCURRENCY_GET_THROTTLE_RATE', default='10/s')
CONCURRENCY_ALAZ_DEFAULT_THROTTLE_RATE = config('CONCURRENCY_ALAZ_DEFAULT_THROTTLE_RATE', default='200/s')
CONCURRENCY_ALAZ_HEALTH_CHECK_THROTTLE_RATE = config('CONCURRENCY_ALAZ_HEALTH_CHECK_THROTTLE_RATE', default='50/s')
CONCURRENCY_THROTTLE_NAME = "alternate"

ROOT_EMAIL = config('ROOT_EMAIL', default='root@getanteon.com')
ROOT_PASSWORD = config('ROOT_PASSWORD', default='ChangeMe123')
SERVICE_MAP_MAX_RESOURCE_COUNT = config("SERVICE_MAP_MAX_RESOURCE_COUNT", cast=int, default=50)
PROMETHEUS_URL = config("PROMETHEUS_URL", default="http://prometheus:9090")
PROMETHEUS_MAX_DATA_POINTS = config("PROMETHEUS_MAX_DATA_POINTS", cast=int, default=11000)
PROMETHEUS_DATA_POINTS = config("PROMETHEUS_DATA_POINTS", cast=int, default=30)
PROMETHEUS_SCRAPE_INTERVAL_SECONDS = config("PROMETHEUS_SCRAPE_INTERVAL_SECONDS", cast=int, default=5)
REDIS_METRICS_KEY = config("REDIS_METRICS_KEY", default="metrics_key")
SELFHOSTED_ENTERPRISE_PLAN_ID = config("SELFHOSTED_ENTERPRISE_PLAN_ID", default="63760")
REDIS_METRICS_EXPIRE_TIME_SECONDS=config("REDIS_METRICS_EXPIRE_TIME_SECONDS", cast=int, default=300)
if settings.ANTEON_ENV == "onprem":
    ENTERPRISE_INSTANCES_LIMIT = 500
    COMMUNITY_INSTANCES_LIMIT = 5
    ENTERPRISE_RETENTION_DAYS = 7
    COMMUNITY_RETENTION_DAYS = 2
    TELEMETRY_DATA_INTERVAL_SECONDS = config("TELEMETRY_DATA_INTERVAL_SECONDS", cast=int, default=3600)
    ANONYMOUS_TELEMETRY_ENABLED = config("ANONYMOUS_TELEMETRY_ENABLED", cast=bool, default=True)
IDEMPOTENCY_KEYS_REDIS_KEY = config("IDEMPOTENCY_KEYS_REDIS_KEY", default="idempotency_keys")
IDEMPOTENCY_KEYS_EXPIRE_TIME_SECONDS = config("IDEMPOTENCY_KEYS_EXPIRE_TIME_SECONDS", cast=int, default=300)

CONN_MAX_AGE = config("CONN_MAX_AGE", cast=int, default=60)  # in seconds. 0 means unlimited, no persistent connections
BULK_BATCH_SIZE = config("BULK_BATCH_SIZE", cast=int, default=800)
ALAZ_SAVE_CONTAINER_EVENTS = config("ALAZ_SAVE_CONTAINER_EVENTS", cast=bool, default=False)
INSTANCE_EXPIRATION_TIME_DAYS = config("INSTANCE_EXPIRATION_TIME_DAYS", cast=int, default=30)
ENDPOINTS_PAGE_SIZE = config ("ENDPOINTS_PAGE_SIZE", cast=int, default=5)
RESOURCE_METRICS_STATUS_CODE_COUNT = config("RESOURCE_METRICS_STATUS_CODE_COUNT", cast=int, default=30)
SILK_ENABLED = config("SILK_ENABLED", cast=bool, default=False)

if SILK_ENABLED:
    SILKY_PYTHON_PROFILER = True
    INSTALLED_APPS.insert(8, 'silk') 
    MIDDLEWARE.insert(1, 'silk.middleware.SilkyMiddleware')

CURRENT_WINDOW_SECONDS = config("CURRENT_WINDOW_SECONDS", cast=int, default=60)
REDIS_IDEMPOTENCY_FIELD = config("REDIS_IDEMPOTENCY_FIELD", default="exists")

NO_HEARTBEAT_MAX_MAIL_LENGTH = config("NO_HEARTBEAT_MAX_MAIL_LENGTH", default=50)
CONCURRENCY_TELEMETRY_THROTTLE_RATE= config("CONCURRENCY_TELEMETRY_THROTTLE_RATE", default="20/s")
TELEMETRY_AUTH_KEY = config("TELEMETRY_AUTH_KEY", default="test_key")

SPAN_GENERATION_INTERVAL_SEC = config("SPAN_GENERATION_INTERVAL_SEC", cast=int, default=30)
DIST_TRACING_SPAN_INTERVAL_SEC = config("DIST_TRACING_SPAN_INTERVAL_SEC", cast=int, default=60)
TRACE_GENERATION_INTERVAL_SEC = config("TRACE_GENERATION_INTERVAL_SEC", cast=int, default=120)
DIST_TRACING_MATCH_LIMIT_SEC = config("DIST_TRACING_MATCH_LIMIT_SEC", cast=int, default=60)
DIST_TRACING_REQUEST_INTERVAL_EXTRA_SECONDS = config("DIST_TRACING_REQUEST_INTERVAL_EXTRA_SECONDS", cast=int, default=180)
DIST_TRACING_SPAN_RETENTION_DAYS = config("DIST_TRACING_SPAN_RETENTION_DAYS", cast=int, default=1)
DIST_TRACING_SPAN_PROCESS_INTERVAL_SECONDS = config("DIST_TRACING_SPAN_PROCESS_INTERVAL_SECONDS", cast=int, default=300)
DIST_TRACING_TRACE_LIST_LIMIT = config("DIST_TRACING_TRACE_LIST_LIMIT", cast=int, default=1500)
DIST_TRACING_TRACE_LIST_DEFAULT = config("DIST_TRACING_TRACE_LIST_DEFAULT", cast=int, default=25)
DIST_TRACING_TRAFFIC_QUEUE = config("DIST_TRACING_TRAFFIC_QUEUE", default='traffic')
DIST_TRACING_TRAFFIC_BATCH_SIZE = config("DIST_TRACING_TRAFFIC_BATCH_SIZE", cast=int, default=800)

CONCURRENCY_ALAZ_TRAFFIC_THROTTLE_RATE = config("CONCURRENCY_ALAZ_TRAFFIC_THROTTLE_RATE", default="100/s")
BACKEND_URL = config("BACKEND_URL", default="http://backend:8008")
CLOUD_ALAZ_BACKEND_URL = config("CLOUD_ALAZ_BACKEND_URL", default="https://api-alaz.getanteon.com/")
CLOUD_ALAZ_BACKEND_USERNAME = config("CLOUD_ALAZ_BACKEND_USERNAME", default="CHANGE_THIS_TO_THE_PROD_USERNAME")
CLOUD_ALAZ_BACKEND_PASSWORD = config("CLOUD_ALAZ_BACKEND_PASSWORD", default="CHANGE_THIS_TO_THE_PROD_PASSWORD")
BACKEND_USERNAME = config("BACKEND_USERNAME", default="backend")
BACKEND_PASSWORD = config("BACKEND_PASSWORD", default="uVtaRDiL8yaYjas6XB2")
ALAZ_BACKEND_USERNAME = config("ALAZ_BACKEND_USERNAME", default="alaz-backend")
ALAZ_BACKEND_PASSWORD = config("ALAZ_BACKEND_PASSWORD", default="jRTyHAbUHYE37hRBgEz")
REQUESTS_QUEUE = config("REQUESTS_QUEUE", default='requests')
RESOURCES_UNUSED_CLEAR_DAYS = config("RESOURCES_UNUSED_CLEAR_DAYS", cast=int, default=5)
CONNECTIONS_QUEUE = config("CONNECTIONS_QUEUE", default='connections')
PODS_TO_DEPLOYMENTS_HSET = config("PODS_TO_DEPLOYMENTS_HSET", default='pods_to_deployments')
PODS_TO_DAEMONSETS_HSET = config("PODS_TO_DAEMONSETS_HSET", default='pods_to_daemonsets')
PODS_TO_STATEFULSETS_HSET = config("PODS_TO_STATEFULSETS_HSET", default='pods_to_statefulsets')

ASGI_APPLICATION = "backend.asgi.application"

CHANNEL_LAYERS = {
    'default': {
        'BACKEND': 'channels_redis.core.RedisChannelLayer',
        'CONFIG': {
            "hosts": [(REDIS_HOST, REDIS_PORT)],
            "capacity": 1500,  # default 100
            "expiry": 1,  # default 60
        },
    },
}

WEBSOCKET_SECRET_KEY = config('WEBSOCKET_SECRET_KEY', default='>1YG*E[e7PG$FDc8GTmIHh-0+XJJTO')

CLICKHOUSE_HOST = config('CLICKHOUSE_HOST', default='selfhosted_alaz_backend_clickhouse')
CLICKHOUSE_PORT = config('CLICKHOUSE_PORT', default=8123, cast=int)
CLICKHOUSE_USER = config('CLICKHOUSE_USER', default='root')
CLICKHOUSE_PASSWORD = config('CLICKHOUSE_PASSWORD', default='6p(W(60_*8teI$si?j')
INITIAL_LOG_COUNT = config('INITIAL_LOG_COUNT', default=100, cast=int)

TRAFFIC_TASK_LOCK = config('TRAFFIC_TASK_LOCK', default='traffic_task_lock')
REQUESTS_TASK_LOCK = config('REQUESTS_TASK_LOCK', default='requests_task_lock')
CONNECTIONS_TASK_LOCK = config('CONNECTIONS_TASK_LOCK', default='connections_task_lock')
TRAFFIC_TASK_TIMEOUT_SECONDS = config('TRAFFIC_TASK_TIMEOUT_SECONDS', cast=int, default=60)
REQUESTS_TASK_TIMEOUT_SECONDS = config('REQUESTS_TASK_TIMEOUT_SECONDS', cast=int, default=60)
CONNECTIONS_TASK_TIMEOUT_SECONDS = config('CONNECTIONS_TASK_TIMEOUT_SECONDS', cast=int, default=60)
LOG_BATCH_SIZE = config('LOG_BATCH_SIZE', cast=int, default=100)
DIST_TRACING_DELETE_BATCH_SIZE = config('DIST_TRACING_DELETE_BATCH_SIZE', cast=int, default=50000)
REQUESTS_DELETE_BULK_BATCH_SIZE = config('REQUESTS_DELETE_BULK_BATCH_SIZE', cast=int, default=2000)
REQUESTS_CLEAR_TASK_LOCK = config('REQUESTS_CLEAR_TASK_LOCK', default='requests_clear_task_lock')
REQUESTS_CLEAR_TASK_TIMEOUT_SECONDS = config('REQUESTS_CLEAR_TASK_TIMEOUT_SECONDS', cast=int, default=4800) # 80 minutes (run hourly)
CONNECTIONS_CLEAR_TASK_LOCK = config('CONNECTIONS_CLEAR_TASK_LOCK', default='connections_clear_task_lock')
CONNECTIONS_CLEAR_TASK_TIMEOUT_SECONDS = config('CONNECTIONS_CLEAR_TASK_TIMEOUT_SECONDS', cast=int, default=4800) # 80 minutes (run hourly)
DIST_TRACING_CLEAR_TASK_LOCK = config('DIST_TRACING_CLEAR_TASK_LOCK', default='dist_tracing_clear_task_lock')
DIST_TRACING_CLEAR_TASK_TIMEOUT_SECONDS = config('DIST_TRACING_CLEAR_TASK_TIMEOUT_SECONDS', cast=int, default=1800) # 30 minutes (run every 10 min)
SPAN_GENERATION_LOCK = config('SPAN_GENERATION_LOCK', default='span_generation_lock')
SPAN_GENERATION_TIMEOUT_SECONDS = config('SPAN_GENERATION_TIMEOUT_SECONDS', cast=int, default=300)
TRACE_GENERATION_LOCK = config('TRACE_GENERATION_LOCK', default='trace_generation_lock')
TRACE_GENERATION_TIMEOUT_SECONDS = config('TRACE_GENERATION_TIMEOUT_SECONDS', cast=int, default=360)
DIST_TRACING_TRAFFIC_RETENTION_MINUTES = config('DIST_TRACING_TRAFFIC_RETENTION_MINUTES', cast=int, default=10)
EVENTS_BULK_BATCH_SIZE = config('EVENTS_BULK_BATCH_SIZE', cast=int, default=100)

REQUESTS_SIZE_KEY = config('REQUESTS_SIZE_KEY', default='requests_size')
CONNECTIONS_SIZE_KEY = config('CONNECTIONS_SIZE_KEY', default='connections_size')
TRACES_SIZE_KEY = config('TRACES_SIZE_KEY', default='traces_size')
LOGS_SIZE_KEY = config('LOGS_SIZE_KEY', default='logs_size')
LOG_BROADCAST_LAG_SECONDS = config('LOG_BROADCAST_LAG_SECONDS', cast=int, default=0)
LOG_CHANNELS_KEY = config('LOG_CHANNELS_KEY', default='log_channels')
LOG_BROADCAST_THREADS = config('LOG_BROADCAST_THREADS', cast=int, default=8)
LOG_FLUSH_PERIOD_SECONDS = config('LOG_FLUSH_PERIOD_SECONDS', cast=float, default=1)
MAX_LOG_LISTENER_THREADS = config('MAX_LOG_LISTENER_THREADS', cast=int, default=30)
LOG_QUEUE_KEY = config('LOG_QUEUE_KEY', default='log_queue')
LOG_BROADCASTER_VERBOSE_LOG = config('LOG_BROADCASTER_VERBOSE_LOG', cast=bool, default=False)
LOG_BROADCASTER_SLEEP_SECONDS = config('LOG_BROADCASTER_SLEEP_SECONDS', cast=float, default=1)
LOG_LISTENER_VERBOSE_LOG = config('LOG_LISTENER_VERBOSE_LOG', cast=bool, default=False)
CELERY_VERBOSE_LOG = config('CELERY_VERBOSE_LOG', cast=bool, default=False)
ORPHANS_CORE_CLEAR_TASK_LOCK = config('ORPHANS_CORE_CLEAR_TASK_LOCK', default='orphans_core_clear_task_lock')
ORPHANS_CORE_CLEAR_TASK_TIMEOUT_SECONDS = config('ORPHANS_CORE_CLEAR_TASK_TIMEOUT_SECONDS', cast=int, default=86_400) # 1 day (run hourly)
ORPHANS_DIST_TRACING_CLEAR_TASK_LOCK = config('ORPHANS_DIST_TRACING_CLEAR_TASK_LOCK', default='orphans_dist_tracing_clear_task_lock')
ORPHANS_DIST_TRACING_CLEAR_TASK_TIMEOUT_SECONDS = config('ORPHANS_DIST_TRACING_CLEAR_TASK_TIMEOUT_SECONDS', cast=int, default=86_400) # 1 day (run hourly)
LOCK_CLUSTER_UPDATE = config('LOCK_CLUSTER_UPDATE', cast=bool, default=False)
KAFKA_EVENTS_CLEAR_TASK_LOCK = config('KAFKA_EVENTS_CLEAR_TASK_LOCK', default='kafka_events_clear_task_lock')
KAFKA_EVENTS_CLEAR_TASK_TIMEOUT_SECONDS = config('KAFKA_EVENTS_CLEAR_TASK_TIMEOUT_SECONDS', cast=int, default=4800) # 80 minutes (run hourly)
KAFKA_EVENTS_QUEUE = config('KAFKA_EVENTS_QUEUE', default='kafka_events')
KAFKA_EVENTS_TASK_LOCK = config('KAFKA_EVENTS_TASK_LOCK', default='kafka_events_task_lock')
KAFKA_EVENTS_TASK_TIMEOUT_SECONDS = config('KAFKA_EVENTS_TASK_TIMEOUT_SECONDS', cast=int, default=60)
KAFKA_SPAN_GENERATION_LOCK = config('KAFKA_SPAN_GENERATION_LOCK', default='kafka_span_generation_lock')
KAFKA_SPAN_GENERATION_TIMEOUT_SECONDS = config('KAFKA_SPAN_GENERATION_TIMEOUT_SECONDS', cast=int, default=300)
PODS_REDIS_KEY = config('PODS_REDIS_KEY', default='pods')
CLUSTERS_REDIS_KEY = config('CLUSTERS_REDIS_KEY', default='clusters')
# TCPDUMP_ENABLED = config('TCPDUMP_ENABLED', cast=bool, default=False)
# TCPDUMP_BATCH_SIZE = config('TCPDUMP_BATCH_SIZE', cast=int, default=10000)
# TCPDUMP_QUEUE = config('TCPDUMP_QUEUE', default='tcpdump')
# TCPDUMP_TO_CLICKHOUSE_TASK_LOCK = config('TCPDUMP_TO_CLICKHOUSE_TASK_LOCK', default='tcpdump_to_clickhouse_task_lock')
# TCPDUMP_TO_CLICKHOUSE_TASK_TIMEOUT_SECONDS = config('TCPDUMP_TO_CLICKHOUSE_TASK_TIMEOUT_SECONDS', cast=int, default=60)
# TCPDUMP_THROTTLE_RATE = config('TCPDUMP_THROTTLE_RATE', default='200/s')

REDIS_MEMORY_LIMIT_MB = config('REDIS_MEMORY_LIMIT_MB', cast=int, default=1000)
POSTGRES_STORAGE_LIMIT_MB = config('POSTGRES_STORAGE_LIMIT_MB', cast=int, default=100_000)
RABBITMQ_MESSAGE_LIMIT = config('RABBITMQ_MESSAGE_LIMIT', cast=int, default=300)
CLICKHOUSE_STORAGE_LIMIT_MB = config('CLICKHOUSE_STORAGE_LIMIT_MB', cast=int, default=100_000)
RABBITMQ_USERNAME = config('RABBITMQ_USERNAME', default='guest')
RABBITMQ_PASSWORD = config('RABBITMQ_PASSWORD', default='guest')
SLACK_BLOAT_NOTIFIER_TOKEN = config('SLACK_BLOAT_NOTIFIER_TOKEN', default='123456789')
BLOAT_NOTIFICATION_ENABLED = config('BLOAT_NOTIFICATION_ENABLED', cast=bool, default=False)
CONTAINERS_REDIS_KEY = config('CONTAINERS_REDIS_KEY', default='containers')
WRITE_TASK_TIMEOUT_SEC = config('WRITE_TASK_TIMEOUT_SEC', cast=int, default=30)
REQUESTS_BATCH_SIZE = config('REQUESTS_BATCH_SIZE', cast=int, default=400)
SERVICE_MAP_DURATION_LOG = config('SERVICE_MAP_DURATION_LOG', cast=bool, default=False)
REQUEST_WRITER_VERBOSE_LOG = config('REQUEST_WRITER_VERBOSE_LOG', cast=bool, default=False)
REQUEST_WRITER_THREADS = config('REQUEST_WRITER_THREADS', cast=int, default=4)
REDIS_CLEAR_ENABLED = config('REDIS_CLEAR_ENABLED', cast=bool, default=True)
REDIS_CLEAR_SIZE_LIMIT_GB = config('REDIS_CLEAR_SIZE_LIMIT_GB', cast=int, default=10)
REQUESTS_BULK_BATCH_SIZE = config('REQUESTS_BULK_BATCH_SIZE', cast=int, default=40_000)

API_CATALOG_PAGE_SIZE=config('API_CATALOG_PAGE_SIZE', cast=int, default=30)
LOG_CHANNELS_MAPPING=config('LOG_CHANNELS_MAPPING', default='log_channels_mapping')
K8S_EVENTS_PAGE_SIZE=config('K8S_EVENTS_PAGE_SIZE', cast=int, default=30)